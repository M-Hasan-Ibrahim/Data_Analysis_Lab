{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c63b64-196c-4025-bda5-5382ceaaf421",
   "metadata": {},
   "source": [
    "# Lab 04 : Image Data Handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427786d9-c4f8-4769-95ca-dcd38189745f",
   "metadata": {},
   "source": [
    "#### Lab Overview\n",
    "\n",
    "This workshop focuses on data handling and preparation in case of a dataset consisting of images.\n",
    "\n",
    "---\n",
    "\n",
    "#### Objective\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3533291",
   "metadata": {},
   "source": [
    "#### What is Image Processing?\n",
    "\n",
    "- **Definition**: Manipulating pixel-based (raster) images to enhance them, extract information, or transform them.\n",
    "- **Domains**:\n",
    "  - **Low-level processing**: Noise removal, contrast adjustment, filtering.\n",
    "  - **Mid-level processing**: Segmentation, feature extraction.\n",
    "  - **High-level processing**: Interpretation, object recognition, scene understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec33a12",
   "metadata": {},
   "source": [
    "#### Data loading\n",
    "\n",
    "| Concept                           | Description                                                        | Syntax (Library)                                                                                                                                                                                                                                                     |\n",
    "| --------------------------------- | ------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Directory Traversal**           | Recursively gather all image file paths in a folder                | `from pathlib import Path`<br>`paths = list(Path('data/images').rglob('*.jpg'))  # pathlib`                                                                                                                                                                          |\n",
    "| **Batch Loading & Preprocessing** | Loop over paths to read, convert color, resize, etc.               | `import cv2`<br>for path in paths:<br>`    img = cv2.imread(str(path))               # BGR image`<br>`    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB`<br>`    img = cv2.resize(img, (224,224))  # resize`<br>`    label = path.stem.split('_')[0]` |\n",
    "| **Saving Processed Images**       | Write your processed arrays back to disk, keeping label subfolders | `from pathlib import Path`<br>`out_dir = Path('processed')/label`<br>`out_dir.mkdir(parents=True, exist_ok=True)`<br>`cv2.imwrite(str(out_dir/path.name), processed_img)  # cv2 + pathlib`                                                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55845d5",
   "metadata": {},
   "source": [
    "#### Digital Image Representation\n",
    "\n",
    "| Concept                              | Description                                        | Syntax (Library)                                                                                                                                                                        |\n",
    "| ------------------------------------ | -------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Grayscale Loading**                | Load image as single-channel (0–255)               | `gray = cv2.imread('path/to/image.jpg', cv2.IMREAD_GRAYSCALE)` (cv2)                                                                                                                    |\n",
    "| **Grayscale Conversion & Normalize** | Decode JPEG → to gray → normalize to [0,1] float32 | `raw = tf.io.read_file('path'); img = tf.image.decode_jpeg(raw, channels=3); gray = tf.image.rgb_to_grayscale(img); gray = tf.image.convert_image_dtype(gray, tf.float32)` (TensorFlow) |\n",
    "| **Display Grayscale**                | Show gray image with colormap                      | `plt.imshow(gray, cmap='gray'); plt.axis('off')` (Matplotlib)                                                                                                                           |\n",
    "| **Color Loading & BGR→RGB**          | Read BGR image and convert to RGB                  | `img_bgr = cv2.imread('path'); img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)` (cv2)                                                                                                |\n",
    "| **Display Color**                    | Show RGB image                                     | `plt.imshow(img_rgb); plt.axis('off')` (Matplotlib)                                                                                                                                     |\n",
    "| **Resize**                           | Resize image to 512×512 px                         | `resized = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)` (cv2)                                                                                                           |\n",
    "| **Resize (TensorFlow)**              | Resize tensor image to 512×512                     | `resized = tf.image.resize(img, [512, 512], method='bilinear')` (TensorFlow)                                                                                                            |\n",
    "| **Figure Scaling**                   | Control display size (inches)                      | `plt.figure(figsize=(6, 6))` (Matplotlib)                                                                                                                                               |\n",
    "| **Load High Bit-Depth**              | Read image preserving original bit depth           | `img16 = cv2.imread('path', cv2.IMREAD_UNCHANGED)` (cv2)                                                                                                                                |\n",
    "| **Scale uint16→uint8**               | Convert 16-bit image to 8-bit                      | `img8 = cv2.convertScaleAbs(img16, alpha=255/65535)` (cv2)                                                                                                                              |\n",
    "| **Normalize dtype**                  | Cast to float32 & scale pixel values to [0,1]      | `img_f32 = tf.image.convert_image_dtype(img, tf.float32)` (TensorFlow)                                                                                                                  |\n",
    "| **BGR→HSV**                          | Convert BGR image to HSV                           | `hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)` (cv2)                                                                                                                                  |\n",
    "| **RGB→HSV (TensorFlow)**             | Convert RGB float image to HSV                     | `hsv_tf = tf.image.rgb_to_hsv(tf.image.convert_image_dtype(img_rgb, tf.float32))` (TensorFlow)                                                                                          |\n",
    "| **BGR→Lab**                          | Convert BGR image to CIELab                        | `lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2Lab)` (cv2)                                                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1acb682",
   "metadata": {},
   "source": [
    "#### Fundamental Operations\n",
    "\n",
    "| Concept                            | Description                                                  | Syntax (Library)                                                                                                                                                                                         |\n",
    "| ---------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Brightness / Contrast**          | Pixel-wise linear scaling & shift                            | `adj = cv2.convertScaleAbs(img, alpha=α, beta=β)` (cv2)<br>`bright = tf.image.adjust_brightness(img_tf, delta)` (TensorFlow)<br>`contr = tf.image.adjust_contrast(img_tf, contrast_factor)` (TensorFlow) |\n",
    "| **Gamma Correction**               | Non-linear mapping: Iout = 255·(Iin/255)ᵞ                    | `gamma_np = np.power(img/255.0, γ) * 255` (NumPy)<br>`img_gc = tf.image.adjust_gamma(img_tf, gamma=γ)` (TensorFlow)                                                                                      |\n",
    "| **Global Thresholding**            | Binary conversion using a fixed threshold                    | `_, th = cv2.threshold(gray, t, 255, cv2.THRESH_BINARY)` (cv2)<br>`binary = tf.where(gray_tf > t, 1, 0)` (TensorFlow)                                                                                    |\n",
    "| **Adaptive Thresholding**          | Local binary conversion per neighborhood                     | `th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blockSize, C)` (cv2)                                                                                           |\n",
    "| **Mean Filter**                    | Linear neighborhood averaging                                | `mean = cv2.blur(img, (k, k))` (cv2)<br>`mean_tf = tf.nn.avg_pool2d(img_batch, ksize=k, strides=1, padding='SAME')` (TensorFlow)                                                                         |\n",
    "| **Gaussian Blur**                  | Weighted linear smoothing                                    | `gblur = cv2.GaussianBlur(img, (k, k), σ)` (cv2)                                                                                                                                                         |\n",
    "| **Sharpening Filter**              | Edge enhancement via convolution                             | `kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])` (NumPy)<br>`sharp = cv2.filter2D(img, -1, kernel)` (cv2)                                                                                      |\n",
    "| **Median Filter**                  | Non-linear neighborhood filter for impulse noise             | `med = cv2.medianBlur(img, k)` (cv2)                                                                                                                                                                     |\n",
    "| **Morphological Opening**          | Erosion → dilation to remove small objects                   | `opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)` (cv2)                                                                                                                                           |\n",
    "| **Morphological Closing**          | Dilation → erosion to fill small holes                       | `closed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)` (cv2)                                                                                                                                          |\n",
    "| **Histogram Equalization**         | Redistribute intensities for global contrast enhancement     | `eq = cv2.equalizeHist(gray)` (cv2)                                                                                                                                                                      |\n",
    "| **DFT / FFT**                      | Convert to frequency domain                                  | `dft = cv2.dft(np.float32(gray), flags=cv2.DFT_COMPLEX_OUTPUT)` (cv2)<br>`fft = tf.signal.fft2d(tf.cast(gray_tf, tf.complex64))` (TensorFlow)                                                            |\n",
    "| **Low-Pass Filtering (Freq-dom)**  | Suppress high-frequency components via frequency-domain mask | `fshift = np.fft.fftshift(dft)` (NumPy)<br>`mask[...] = 1  # central low-pass mask` (NumPy)<br>`filt = fshift * mask[:, :, None]` (NumPy)<br>`img_back = cv2.idft(np.fft.ifftshift(filt))` (cv2)         |\n",
    "| **High-Pass Filtering (Freq-dom)** | Suppress low-frequency components via inverted mask          | Same as low-pass but invert mask (cv2/NumPy)                                                                                                                                                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1c294",
   "metadata": {},
   "source": [
    "#### Geometric Transformations\n",
    "\n",
    "| Concept                  | Description                                                                                                  | Syntax (Library)                                                                                                                                                                                                           |\n",
    "| ------------------------ | ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Scaling**              | Enlarge or shrink an image by scaling factors along X/Y axes                                                 | `rescaled = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR)`                                                                                                                                         |\n",
    "| **Translation**          | Shift an image by (tx, ty) pixels                                                                            | `M = np.float32([[1, 0, tx], [0, 1, ty]])`<br>`translated = cv2.warpAffine(img, M, (width, height))`                                                                                                                       |\n",
    "| **Rotation**             | Rotate an image by θ degrees around its center                                                               | `center=(w/2,h/2)`<br>`M = cv2.getRotationMatrix2D(center, angle, scale=1.0)`<br>`rotated = cv2.warpAffine(img, M, (w, h))`<br>`python<br># TensorFlow Addons<br>rotated_tf = tfa.image.rotate(img_tf, angles_in_radians)` |\n",
    "| **Affine Transform**     | 6-parameter linear transform (preserves parallelism) mapping three source points to three destinations       | `pts1 = np.float32([[x1,y1],[x2,y2],[x3,y3]])`<br>`pts2 = np.float32([[x1',y1'],[x2',y2'],[x3',y3']])`<br>`M = cv2.getAffineTransform(pts1, pts2)`<br>`affine = cv2.warpAffine(img, M, (w, h))`                            |\n",
    "| **Projective Transform** | 8-parameter perspective transform (handles vanishing points), mapping four source to four destination points | `src = np.float32([[x1,y1],[x2,y2],[x3,y3],[x4,y4]])`<br>`dst = np.float32([[x1',y1'],[x2',y2'],[x3',y3'],[x4',y4']])`<br>`M = cv2.getPerspectiveTransform(src, dst)`<br>`persp = cv2.warpPerspective(img, M, (w, h))`     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc4a88",
   "metadata": {},
   "source": [
    "#### Image Segmentation\n",
    "\n",
    "| Concept                                        | Description                                                              | Syntax (Library)                                                                                                                                                      |\n",
    "| ---------------------------------------------- | ------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Image Segmentation**                         | Dividing an image into meaningful regions or objects.                    | —                                                                                                                                                                     |\n",
    "| **Global Thresholding**                        | Segment image by applying a single intensity cutoff.                     | `_, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)` (cv2)<br>`th_tf = tf.where(gray_tf > 0.5, 1.0, 0.0)` (TensorFlow)                                          |\n",
    "| **Adaptive Thresholding**                      | Local threshold based on neighborhood statistics (handles uneven light). | `clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)); th_adapt = clahe.apply(gray)` (cv2)<br>`# TF: use sliding window & tf.where for custom local thresholds` |\n",
    "| **Edge-based Segmentation (Canny + Contours)** | Detect edges, then trace contours to outline objects.                    | `edges = cv2.Canny(gray, 100, 200)`<br>`contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)` (cv2)                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd35d97",
   "metadata": {},
   "source": [
    "#### Typical Workflow\n",
    "\n",
    "1. **Acquire & load** images (DICOM/Png/Jpeg).\n",
    "2. **Preprocess**: resize, normalize, denoise, correct illumination.\n",
    "3. **Transform**: apply filters, histogram equalization.\n",
    "4. **Segment** regions of interest.\n",
    "5. **Extract** features or feed into a deep model.\n",
    "6. **Post-process**: morphological cleanup, threshold refinement.\n",
    "7. **Analyze** or visualize results.\n",
    "\n",
    "#### Practical Tips\n",
    "\n",
    "- Always inspect a few raw images to understand noise patterns and artifacts.\n",
    "- Start with simple filters (median, Gaussian) before jumping to complex methods.\n",
    "- Normalize pixel values (e.g., scale to [0, 1]) when using neural networks.\n",
    "- Use cross-validation and pay attention to data leakage, especially in medical imaging.\n",
    "- Leverage pre-trained models and transfer learning to save time and data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c006a-6078-4d80-a563-95568e011733",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Hands-on Activity\n",
    "\n",
    "For the assigned dataset perform the following tasks: <br>\n",
    "**Task 1** : Load all the image data, their bounding box coordinates, and filename <br>\n",
    "**Task 2** : create a dataframe to store in it for each image original filename, bounding box coordinates, class, and modified filename. <br>\n",
    "**Task 3** : create a new directory containing 4 subdirectries (one directory for each class) <br>\n",
    "**Task 4** : for each loaded extract the class from the filename and store it in the correct new subdirectory created and rename image to be `img_[i].jpg` <br>\n",
    "**Task 5** : add the necessary data about the image in the created dataframe <br>\n",
    "**Task 6** : load and display 5 images for each class to tests image processing on.\n",
    "\n",
    "- for each image processing step display the output to see the change done on the image.\n",
    "- display images of same class on the same row <br>\n",
    "\n",
    "**Task 7** : Apply at least 5 suitable image processing techniques from the mentioned above. Explain why you selected a certain method and how did it affect the image. (each image processing technique in a seperate code block)\n",
    "\n",
    "##### Note the following:\n",
    "\n",
    "- When necessary display/add briefly the logic/reasoning of a data procedure done.\n",
    "- Write clean code, allocate at least 1 code block for each task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "263c8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41029ea0-2f09-47e3-bfa4-7dd3a76ce72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana_dataset\\train\\labels\\musa-acuminata-unripe-627d985c-2653-11ec-a294-d8c4975e38aa_jpg.rf.82f61c4245036cc83baeef3cd34c57d6.txt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Path.replace() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m image_path_to_drop \u001b[38;5;241m=\u001b[39m label_path\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m image_path_to_drop \u001b[38;5;241m=\u001b[39m \u001b[43mimage_path_to_drop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# os.remove(label_path)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# os.remove(image_path_to_drop)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_path_to_drop)\n",
      "\u001b[1;31mTypeError\u001b[0m: Path.replace() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "#task 1\n",
    "\n",
    "path_to_data = Path('banana_dataset')\n",
    "splits = ['train', 'valid', 'test']\n",
    "image_data = []\n",
    "\n",
    "# Go through each split (train, valid, test)\n",
    "for split in splits:\n",
    "    images_dir = path_to_data / split / 'images'\n",
    "    labels_dir = path_to_data / split / 'labels'\n",
    "\n",
    "    image_paths = list(images_dir.glob('*.jpg'))\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        label_path = labels_dir / img_path.with_suffix('.txt').name\n",
    "\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            line = label_file.readline()\n",
    "\n",
    "\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5: #drop image and label if found\n",
    "            print(f\"{label_path}\")\n",
    "            image_path_to_drop = label_path.with_suffix('.jpg')\n",
    "            #image_path_to_drop = image_path_to_drop.replace(r\"\\labels\", r\"\\images\")\n",
    "            # os.remove(label_path)\n",
    "            # os.remove(image_path_to_drop)\n",
    "            print(image_path_to_drop)\n",
    "            continue\n",
    "\n",
    "\n",
    "        class_id = int(parts[0])\n",
    "        x_center, y_center, width, height = map(float, parts[1:])\n",
    "\n",
    "        image_data.append({\n",
    "            'image_path': str(img_path),\n",
    "            'original_filename': img_path.name,\n",
    "            'class_id': class_id,\n",
    "            'x_center': x_center,\n",
    "            'y_center': y_center,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d4b0180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 799\n"
     ]
    }
   ],
   "source": [
    "#task 1 _ test\n",
    "print(f\"Number of images: {len(image_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   original_filename  class_id  x_center  \\\n",
      "0  musa-acuminata-overripe-9d459010-1d0a-11ec-89c...         0  0.498958   \n",
      "1  musa-acuminata-overripe-9d6229db-1d0a-11ec-90a...         0  0.502083   \n",
      "2  musa-acuminata-overripe-9d648d3b-1d0a-11ec-838...         0  0.495833   \n",
      "3  musa-acuminata-overripe-9d9b5da1-1d0a-11ec-a47...         0  0.498958   \n",
      "4  musa-acuminata-overripe-9dac0cb7-1d0a-11ec-83d...         0  0.498958   \n",
      "\n",
      "   y_center     width    height splitted_to  \n",
      "0  0.623611  0.997917  0.652778       train  \n",
      "1  0.581944  0.895833  0.558333       train  \n",
      "2  0.409722  0.895833  0.563889       train  \n",
      "3  0.500000  0.997917  0.611111       train  \n",
      "4  0.479167  0.997917  0.958333       train  \n"
     ]
    }
   ],
   "source": [
    "#task 2\n",
    "\n",
    "df = pd.DataFrame(image_data)\n",
    "\n",
    "#df.to_csv('.\\data\\lab_04_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29d65909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>original_filename</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banana_dataset\\train\\images\\musa-acuminata-ove...</td>\n",
       "      <td>musa-acuminata-overripe-9d459010-1d0a-11ec-89c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.623611</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana_dataset\\train\\images\\musa-acuminata-ove...</td>\n",
       "      <td>musa-acuminata-overripe-9d6229db-1d0a-11ec-90a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502083</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana_dataset\\train\\images\\musa-acuminata-ove...</td>\n",
       "      <td>musa-acuminata-overripe-9d648d3b-1d0a-11ec-838...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.563889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banana_dataset\\train\\images\\musa-acuminata-ove...</td>\n",
       "      <td>musa-acuminata-overripe-9d9b5da1-1d0a-11ec-a47...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banana_dataset\\train\\images\\musa-acuminata-ove...</td>\n",
       "      <td>musa-acuminata-overripe-9dac0cb7-1d0a-11ec-83d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>banana_dataset\\test\\images\\musa-acuminata-over...</td>\n",
       "      <td>musa-acuminata-overripe-a00bd29a-1d0a-11ec-b8c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>banana_dataset\\test\\images\\musa-acuminata-over...</td>\n",
       "      <td>musa-acuminata-overripe-a01c81c2-1d0a-11ec-96d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536458</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.761111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>banana_dataset\\test\\images\\musa-acuminata-over...</td>\n",
       "      <td>musa-acuminata-overripe-a0260a6b-1d0a-11ec-888...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.855556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>banana_dataset\\test\\images\\musa-acuminata-over...</td>\n",
       "      <td>musa-acuminata-overripe-a04e8f14-1d0a-11ec-a09...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415625</td>\n",
       "      <td>0.498611</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.997222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>banana_dataset\\test\\images\\musa-acuminata-over...</td>\n",
       "      <td>musa-acuminata-overripe-a1c4c199-1d0a-11ec-a5c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.480556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  \\\n",
       "0    banana_dataset\\train\\images\\musa-acuminata-ove...   \n",
       "1    banana_dataset\\train\\images\\musa-acuminata-ove...   \n",
       "2    banana_dataset\\train\\images\\musa-acuminata-ove...   \n",
       "3    banana_dataset\\train\\images\\musa-acuminata-ove...   \n",
       "4    banana_dataset\\train\\images\\musa-acuminata-ove...   \n",
       "..                                                 ...   \n",
       "794  banana_dataset\\test\\images\\musa-acuminata-over...   \n",
       "795  banana_dataset\\test\\images\\musa-acuminata-over...   \n",
       "796  banana_dataset\\test\\images\\musa-acuminata-over...   \n",
       "797  banana_dataset\\test\\images\\musa-acuminata-over...   \n",
       "798  banana_dataset\\test\\images\\musa-acuminata-over...   \n",
       "\n",
       "                                     original_filename  class_id  x_center  \\\n",
       "0    musa-acuminata-overripe-9d459010-1d0a-11ec-89c...         0  0.498958   \n",
       "1    musa-acuminata-overripe-9d6229db-1d0a-11ec-90a...         0  0.502083   \n",
       "2    musa-acuminata-overripe-9d648d3b-1d0a-11ec-838...         0  0.495833   \n",
       "3    musa-acuminata-overripe-9d9b5da1-1d0a-11ec-a47...         0  0.498958   \n",
       "4    musa-acuminata-overripe-9dac0cb7-1d0a-11ec-83d...         0  0.498958   \n",
       "..                                                 ...       ...       ...   \n",
       "794  musa-acuminata-overripe-a00bd29a-1d0a-11ec-b8c...         0  0.498958   \n",
       "795  musa-acuminata-overripe-a01c81c2-1d0a-11ec-96d...         0  0.536458   \n",
       "796  musa-acuminata-overripe-a0260a6b-1d0a-11ec-888...         0  0.498958   \n",
       "797  musa-acuminata-overripe-a04e8f14-1d0a-11ec-a09...         0  0.415625   \n",
       "798  musa-acuminata-overripe-a1c4c199-1d0a-11ec-a5c...         0  0.481250   \n",
       "\n",
       "     y_center     width    height  \n",
       "0    0.623611  0.997917  0.652778  \n",
       "1    0.581944  0.895833  0.558333  \n",
       "2    0.409722  0.895833  0.563889  \n",
       "3    0.500000  0.997917  0.611111  \n",
       "4    0.479167  0.997917  0.958333  \n",
       "..        ...       ...       ...  \n",
       "794  0.423611  0.997917  0.558333  \n",
       "795  0.541667  0.906250  0.761111  \n",
       "796  0.427778  0.997917  0.855556  \n",
       "797  0.498611  0.493750  0.997222  \n",
       "798  0.462500  0.887500  0.480556  \n",
       "\n",
       "[799 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 799 entries, 0 to 798\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   image_path         799 non-null    object \n",
      " 1   original_filename  799 non-null    object \n",
      " 2   class_id           799 non-null    int64  \n",
      " 3   x_center           799 non-null    float64\n",
      " 4   y_center           799 non-null    float64\n",
      " 5   width              799 non-null    float64\n",
      " 6   height             799 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 43.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#task 2 _ display\n",
    "df = pd.read_csv(\".\\data\\lab_04_A.csv\")\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e288c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdirectories created:\n",
      "{0: 'processed_images\\\\class_0', 1: 'processed_images\\\\class_1', 2: 'processed_images\\\\class_2', 3: 'processed_images\\\\class_3'}\n"
     ]
    }
   ],
   "source": [
    "#task 3\n",
    "\n",
    "processed_directory_path = 'processed_images'\n",
    "os.makedirs(processed_directory_path, exist_ok=True)\n",
    "\n",
    "\n",
    "class_dirs = {} #to be used in task 4 \n",
    "\n",
    "for class_id in range(4):\n",
    "    class_path = os.path.join(processed_directory_path, f'class_{class_id}')\n",
    "    os.makedirs(class_path, exist_ok=True)\n",
    "    class_dirs[class_id] = class_path\n",
    "\n",
    "print(\"Subdirectories created:\")\n",
    "print(class_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae74160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 4\n",
    "\n",
    "# Track new paths\n",
    "new_paths = []\n",
    "\n",
    "# Go through each row in the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    class_id = row['class_id']\n",
    "    src_path = row['image_path']\n",
    "    dst_filename = row['modified_filename']\n",
    "    dst_path = os.path.join(class_dirs[class_id], dst_filename)\n",
    "\n",
    "    # Copy the file to the new location\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "    # Store new path\n",
    "    new_paths.append(dst_path)\n",
    "\n",
    "# Add the new image path to the DataFrame\n",
    "df['new_path'] = new_paths\n",
    "\n",
    "# Preview updated DataFrame\n",
    "print(df[['original_filename', 'class_id', 'modified_filename', 'new_path']].head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
