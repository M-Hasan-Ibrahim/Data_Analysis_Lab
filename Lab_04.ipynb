{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c63b64-196c-4025-bda5-5382ceaaf421",
   "metadata": {},
   "source": [
    "# Lab 02 : Image Data Handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427786d9-c4f8-4769-95ca-dcd38189745f",
   "metadata": {},
   "source": [
    "#### Lab Overview\n",
    "\n",
    "This workshop focuses on data handling and preparation in case of a dataset consisting of images.\n",
    "\n",
    "---\n",
    "\n",
    "#### Objective\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3533291",
   "metadata": {},
   "source": [
    "#### What is Image Processing?\n",
    "\n",
    "- **Definition**: Manipulating pixel-based (raster) images to enhance them, extract information, or transform them.\n",
    "- **Domains**:\n",
    "  - **Low-level processing**: Noise removal, contrast adjustment, filtering.\n",
    "  - **Mid-level processing**: Segmentation, feature extraction.\n",
    "  - **High-level processing**: Interpretation, object recognition, scene understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec33a12",
   "metadata": {},
   "source": [
    "#### Data loading\n",
    "\n",
    "| Concept                           | Description                                                        | Syntax (Library)                                                                                                                                                                                                                                                     |\n",
    "| --------------------------------- | ------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Directory Traversal**           | Recursively gather all image file paths in a folder                | `from pathlib import Path`<br>`paths = list(Path('data/images').rglob('*.jpg'))  # pathlib`                                                                                                                                                                          |\n",
    "| **Batch Loading & Preprocessing** | Loop over paths to read, convert color, resize, etc.               | `import cv2`<br>for path in paths:<br>`    img = cv2.imread(str(path))               # BGR image`<br>`    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB`<br>`    img = cv2.resize(img, (224,224))  # resize`<br>`    label = path.stem.split('_')[0]` |\n",
    "| **Saving Processed Images**       | Write your processed arrays back to disk, keeping label subfolders | `from pathlib import Path`<br>`out_dir = Path('processed')/label`<br>`out_dir.mkdir(parents=True, exist_ok=True)`<br>`cv2.imwrite(str(out_dir/path.name), processed_img)  # cv2 + pathlib`                                                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55845d5",
   "metadata": {},
   "source": [
    "#### Digital Image Representation\n",
    "\n",
    "| Concept                              | Description                                        | Syntax (Library)                                                                                                                                                                        |\n",
    "| ------------------------------------ | -------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Grayscale Loading**                | Load image as single-channel (0–255)               | `gray = cv2.imread('path/to/image.jpg', cv2.IMREAD_GRAYSCALE)` (cv2)                                                                                                                    |\n",
    "| **Grayscale Conversion & Normalize** | Decode JPEG → to gray → normalize to [0,1] float32 | `raw = tf.io.read_file('path'); img = tf.image.decode_jpeg(raw, channels=3); gray = tf.image.rgb_to_grayscale(img); gray = tf.image.convert_image_dtype(gray, tf.float32)` (TensorFlow) |\n",
    "| **Display Grayscale**                | Show gray image with colormap                      | `plt.imshow(gray, cmap='gray'); plt.axis('off')` (Matplotlib)                                                                                                                           |\n",
    "| **Color Loading & BGR→RGB**          | Read BGR image and convert to RGB                  | `img_bgr = cv2.imread('path'); img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)` (cv2)                                                                                                |\n",
    "| **Display Color**                    | Show RGB image                                     | `plt.imshow(img_rgb); plt.axis('off')` (Matplotlib)                                                                                                                                     |\n",
    "| **Resize**                           | Resize image to 512×512 px                         | `resized = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)` (cv2)                                                                                                           |\n",
    "| **Resize (TensorFlow)**              | Resize tensor image to 512×512                     | `resized = tf.image.resize(img, [512, 512], method='bilinear')` (TensorFlow)                                                                                                            |\n",
    "| **Figure Scaling**                   | Control display size (inches)                      | `plt.figure(figsize=(6, 6))` (Matplotlib)                                                                                                                                               |\n",
    "| **Load High Bit-Depth**              | Read image preserving original bit depth           | `img16 = cv2.imread('path', cv2.IMREAD_UNCHANGED)` (cv2)                                                                                                                                |\n",
    "| **Scale uint16→uint8**               | Convert 16-bit image to 8-bit                      | `img8 = cv2.convertScaleAbs(img16, alpha=255/65535)` (cv2)                                                                                                                              |\n",
    "| **Normalize dtype**                  | Cast to float32 & scale pixel values to [0,1]      | `img_f32 = tf.image.convert_image_dtype(img, tf.float32)` (TensorFlow)                                                                                                                  |\n",
    "| **BGR→HSV**                          | Convert BGR image to HSV                           | `hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)` (cv2)                                                                                                                                  |\n",
    "| **RGB→HSV (TensorFlow)**             | Convert RGB float image to HSV                     | `hsv_tf = tf.image.rgb_to_hsv(tf.image.convert_image_dtype(img_rgb, tf.float32))` (TensorFlow)                                                                                          |\n",
    "| **BGR→Lab**                          | Convert BGR image to CIELab                        | `lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2Lab)` (cv2)                                                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1acb682",
   "metadata": {},
   "source": [
    "#### Fundamental Operations\n",
    "\n",
    "| Concept                            | Description                                                  | Syntax (Library)                                                                                                                                                                                         |\n",
    "| ---------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Brightness / Contrast**          | Pixel-wise linear scaling & shift                            | `adj = cv2.convertScaleAbs(img, alpha=α, beta=β)` (cv2)<br>`bright = tf.image.adjust_brightness(img_tf, delta)` (TensorFlow)<br>`contr = tf.image.adjust_contrast(img_tf, contrast_factor)` (TensorFlow) |\n",
    "| **Gamma Correction**               | Non-linear mapping: Iout = 255·(Iin/255)ᵞ                    | `gamma_np = np.power(img/255.0, γ) * 255` (NumPy)<br>`img_gc = tf.image.adjust_gamma(img_tf, gamma=γ)` (TensorFlow)                                                                                      |\n",
    "| **Global Thresholding**            | Binary conversion using a fixed threshold                    | `_, th = cv2.threshold(gray, t, 255, cv2.THRESH_BINARY)` (cv2)<br>`binary = tf.where(gray_tf > t, 1, 0)` (TensorFlow)                                                                                    |\n",
    "| **Adaptive Thresholding**          | Local binary conversion per neighborhood                     | `th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blockSize, C)` (cv2)                                                                                           |\n",
    "| **Mean Filter**                    | Linear neighborhood averaging                                | `mean = cv2.blur(img, (k, k))` (cv2)<br>`mean_tf = tf.nn.avg_pool2d(img_batch, ksize=k, strides=1, padding='SAME')` (TensorFlow)                                                                         |\n",
    "| **Gaussian Blur**                  | Weighted linear smoothing                                    | `gblur = cv2.GaussianBlur(img, (k, k), σ)` (cv2)                                                                                                                                                         |\n",
    "| **Sharpening Filter**              | Edge enhancement via convolution                             | `kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])` (NumPy)<br>`sharp = cv2.filter2D(img, -1, kernel)` (cv2)                                                                                      |\n",
    "| **Median Filter**                  | Non-linear neighborhood filter for impulse noise             | `med = cv2.medianBlur(img, k)` (cv2)                                                                                                                                                                     |\n",
    "| **Morphological Opening**          | Erosion → dilation to remove small objects                   | `opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)` (cv2)                                                                                                                                           |\n",
    "| **Morphological Closing**          | Dilation → erosion to fill small holes                       | `closed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)` (cv2)                                                                                                                                          |\n",
    "| **Histogram Equalization**         | Redistribute intensities for global contrast enhancement     | `eq = cv2.equalizeHist(gray)` (cv2)                                                                                                                                                                      |\n",
    "| **DFT / FFT**                      | Convert to frequency domain                                  | `dft = cv2.dft(np.float32(gray), flags=cv2.DFT_COMPLEX_OUTPUT)` (cv2)<br>`fft = tf.signal.fft2d(tf.cast(gray_tf, tf.complex64))` (TensorFlow)                                                            |\n",
    "| **Low-Pass Filtering (Freq-dom)**  | Suppress high-frequency components via frequency-domain mask | `fshift = np.fft.fftshift(dft)` (NumPy)<br>`mask[...] = 1  # central low-pass mask` (NumPy)<br>`filt = fshift * mask[:, :, None]` (NumPy)<br>`img_back = cv2.idft(np.fft.ifftshift(filt))` (cv2)         |\n",
    "| **High-Pass Filtering (Freq-dom)** | Suppress low-frequency components via inverted mask          | Same as low-pass but invert mask (cv2/NumPy)                                                                                                                                                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1c294",
   "metadata": {},
   "source": [
    "#### Geometric Transformations\n",
    "\n",
    "| Concept                  | Description                                                                                                  | Syntax (Library)                                                                                                                                                                                                           |\n",
    "| ------------------------ | ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Scaling**              | Enlarge or shrink an image by scaling factors along X/Y axes                                                 | `rescaled = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR)`                                                                                                                                         |\n",
    "| **Translation**          | Shift an image by (tx, ty) pixels                                                                            | `M = np.float32([[1, 0, tx], [0, 1, ty]])`<br>`translated = cv2.warpAffine(img, M, (width, height))`                                                                                                                       |\n",
    "| **Rotation**             | Rotate an image by θ degrees around its center                                                               | `center=(w/2,h/2)`<br>`M = cv2.getRotationMatrix2D(center, angle, scale=1.0)`<br>`rotated = cv2.warpAffine(img, M, (w, h))`<br>`python<br># TensorFlow Addons<br>rotated_tf = tfa.image.rotate(img_tf, angles_in_radians)` |\n",
    "| **Affine Transform**     | 6-parameter linear transform (preserves parallelism) mapping three source points to three destinations       | `pts1 = np.float32([[x1,y1],[x2,y2],[x3,y3]])`<br>`pts2 = np.float32([[x1',y1'],[x2',y2'],[x3',y3']])`<br>`M = cv2.getAffineTransform(pts1, pts2)`<br>`affine = cv2.warpAffine(img, M, (w, h))`                            |\n",
    "| **Projective Transform** | 8-parameter perspective transform (handles vanishing points), mapping four source to four destination points | `src = np.float32([[x1,y1],[x2,y2],[x3,y3],[x4,y4]])`<br>`dst = np.float32([[x1',y1'],[x2',y2'],[x3',y3'],[x4',y4']])`<br>`M = cv2.getPerspectiveTransform(src, dst)`<br>`persp = cv2.warpPerspective(img, M, (w, h))`     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc4a88",
   "metadata": {},
   "source": [
    "#### Image Segmentation\n",
    "\n",
    "| Concept                                        | Description                                                              | Syntax (Library)                                                                                                                                                      |\n",
    "| ---------------------------------------------- | ------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Image Segmentation**                         | Dividing an image into meaningful regions or objects.                    | —                                                                                                                                                                     |\n",
    "| **Global Thresholding**                        | Segment image by applying a single intensity cutoff.                     | `_, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)` (cv2)<br>`th_tf = tf.where(gray_tf > 0.5, 1.0, 0.0)` (TensorFlow)                                          |\n",
    "| **Adaptive Thresholding**                      | Local threshold based on neighborhood statistics (handles uneven light). | `clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)); th_adapt = clahe.apply(gray)` (cv2)<br>`# TF: use sliding window & tf.where for custom local thresholds` |\n",
    "| **Edge-based Segmentation (Canny + Contours)** | Detect edges, then trace contours to outline objects.                    | `edges = cv2.Canny(gray, 100, 200)`<br>`contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)` (cv2)                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd35d97",
   "metadata": {},
   "source": [
    "#### Typical Workflow\n",
    "\n",
    "1. **Acquire & load** images (DICOM/Png/Jpeg).\n",
    "2. **Preprocess**: resize, normalize, denoise, correct illumination.\n",
    "3. **Transform**: apply filters, histogram equalization.\n",
    "4. **Segment** regions of interest.\n",
    "5. **Extract** features or feed into a deep model.\n",
    "6. **Post-process**: morphological cleanup, threshold refinement.\n",
    "7. **Analyze** or visualize results.\n",
    "\n",
    "#### Practical Tips\n",
    "\n",
    "- Always inspect a few raw images to understand noise patterns and artifacts.\n",
    "- Start with simple filters (median, Gaussian) before jumping to complex methods.\n",
    "- Normalize pixel values (e.g., scale to [0, 1]) when using neural networks.\n",
    "- Use cross-validation and pay attention to data leakage, especially in medical imaging.\n",
    "- Leverage pre-trained models and transfer learning to save time and data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c006a-6078-4d80-a563-95568e011733",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Hands-on Activity\n",
    "\n",
    "For the assigned dataset perform the following tasks: <br>\n",
    "**Task 1** : Load all the image data, their bounding box coordinates, and filename <br>\n",
    "**Task 2** : create a dataframe to store in it for each image original filename, bounding box coordinates, class, and modified filename. <br>\n",
    "**Task 3** : create a new directory containing 4 subdirectries (one directory for each class) <br>\n",
    "**Task 4** : for each loaded extract the class from the filename and store it in the correct new subdirectory created and rename image to be `img_[i].jpg` <br>\n",
    "**Task 5** : add the necessary data about the image in the created dataframe <br>\n",
    "**Task 6** : load and display 5 images for each class to tests image processing on.\n",
    "\n",
    "- for each image processing step display the output to see the change done on the image.\n",
    "- display images of same class on the same row <br>\n",
    "\n",
    "**Task 7** : Apply at least 5 suitable image processing techniques from the mentioned above. Explain why you selected a certain method and how did it affect the image. (each image processing technique in a seperate code block)\n",
    "\n",
    "##### Note the following:\n",
    "\n",
    "- When necessary display/add briefly the logic/reasoning of a data procedure done.\n",
    "- Write clean code, allocate at least 1 code block for each task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41029ea0-2f09-47e3-bfa4-7dd3a76ce72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
