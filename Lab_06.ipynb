{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b0cb78",
   "metadata": {},
   "source": [
    "# Lab 06 : Image Data Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c909d",
   "metadata": {},
   "source": [
    "#### Lab Overview\n",
    "\n",
    "This workshop focuses on building a machine learning model that is able to classify images using neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43612e",
   "metadata": {},
   "source": [
    "#### Dataset Loading\n",
    "\n",
    "**Definition:**\n",
    "Organize your images into class-named subfolders and use TensorFlow’s high-level API to load, resize, batch, and normalize them for training.\n",
    "\n",
    "**Directory Structure:**\n",
    "\n",
    "```\n",
    "data/\n",
    "├── train/\n",
    "│   ├── class_a/\n",
    "│   │   ├── img001.jpg\n",
    "│   │   └── img002.jpg\n",
    "│   └── class_b/\n",
    "│       ├── img101.jpg\n",
    "│       └── img102.jpg\n",
    "├── validation/\n",
    "│   ├── class_a/\n",
    "│   └── class_b/\n",
    "└── test/\n",
    "    ├── class_a/\n",
    "    └── class_b/\n",
    "```\n",
    "\n",
    "**Loading the images from directory**\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'directory path',\n",
    "    labels=,\n",
    "    label_mode=,\n",
    "    image_size=,\n",
    "    batch_size=,\n",
    "    shuffle=,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "**Explanation of Key Parameters:**\n",
    "\n",
    "- **`directory`**: Root path containing class subfolders. ex: `data/train` in case of loading training dataset\n",
    "- **`labels='inferred'`**: Automatically assign labels based on subfolder names.\n",
    "- **`label_mode`**:\n",
    "\n",
    "  - `'categorical'` → one-hot vectors,\n",
    "  - `'int'` → integer indices,\n",
    "  - `'binary'` → single 0/1 label (for 2-class problems).\n",
    "\n",
    "- **`image_size=(H, W)`**: Resize each image to this shape. (based on model and image resolution)\n",
    "- **`batch_size`**: How many images to return per batch (affects training speed/memory).\n",
    "- **`shuffle` & `seed`**: Randomize sample order; seed ensures reproducibility. Usually shuffle is `True` for training and `False` for testing and validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9b1e3",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "\n",
    "**Definition:**\n",
    "Dynamically apply random transformations to your training images to increase dataset diversity and help your model generalize.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Configure augmentation parameters\n",
    "gen = ImageDataGenerator(\n",
    "    rotation_range=30,            # Random rotations in the range ±30°\n",
    "    width_shift_range=0.1,        # Horizontal shifts up to 10% of image width\n",
    "    height_shift_range=0.1,       # Vertical shifts up to 10% of image height\n",
    "    brightness_range=[0.8, 1.2],  # Random brightness adjustments between 80% and 120%\n",
    "    horizontal_flip=True,         # Randomly flip images left ↔ right\n",
    "    zoom_range=0.2,               # Random zoom in range [80%, 120%]\n",
    "    shear_range=0.1               # Shear intensity (in radians) up to ±0.1\n",
    ")\n",
    "\n",
    "# 2. Build an iterator that reads from directory and applies augmentations\n",
    "iterator = gen.flow_from_directory(\n",
    "    'data/train',                 # Root directory containing subfolders per class\n",
    "    target_size=(224, 224),       # Resize all images to 224×224\n",
    "    batch_size=32,                # Number of images per batch\n",
    "    class_mode='categorical'      # Return one-hot encoded labels (use 'binary' for 2 classes)\n",
    ")\n",
    "```\n",
    "\n",
    "**Explanation of Key Parameters:**\n",
    "\n",
    "- `rotation_range`: Degree range for random rotations.\n",
    "- `width_shift_range` & `height_shift_range`: Fraction of total width/height for random translations.\n",
    "- `brightness_range`: Tuple `[min, max]` to scale pixel intensity.\n",
    "- `horizontal_flip`: Boolean to enable random left–right flips.\n",
    "- `zoom_range`: Float or `[min, max]` for random zoom.\n",
    "- `shear_range`: Shear angle in radians for affine transformations.\n",
    "- `flow_from_directory`:\n",
    "\n",
    "  - **`'data/train'`**: folder with subdirectories named by class.\n",
    "  - **`target_size`**: uniformly resizes input images.\n",
    "  - **`batch_size`**: number of samples per generated batch.\n",
    "  - **`class_mode`**: how labels are returned (`'categorical'`, `'binary'`, `'sparse'`, or `None`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381279c",
   "metadata": {},
   "source": [
    "#### CNN Architecture in Keras\n",
    "\n",
    "to get layers to build the architectural blocks of the CNN you need the following import:\n",
    "\n",
    "`from tensorflow.keras import layers`\n",
    "\n",
    "Break your model into two logical parts:\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Feature Extraction Block\n",
    "\n",
    "**Definition:** Stacks of convolutional filters + downsampling to learn spatial hierarchies of features (edges → textures → shapes).\n",
    "\n",
    "| Layer                  | Purpose & When to Use                                                           | Syntax Example                                                                         |\n",
    "| ---------------------- | ------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n",
    "| **Conv2D**             | Learn local patterns; start with small filters (3×3) and double filters deeper. | `layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224,224,3))` |\n",
    "| **BatchNormalization** | Stabilize and accelerate training by normalizing activations.                   | `layers.BatchNormalization()`                                                          |\n",
    "| **Activation**         | Apply non-linearity (if not in Conv2D).                                         | `layers.Activation('relu')`                                                            |\n",
    "| **MaxPooling2D**       | Downsample spatial dimensions by taking max in each region.                     | `layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))`                                  |\n",
    "| **Dropout**            | Regularize; randomly zero inputs to reduce overfitting.                         | `layers.Dropout(0.25)`                                                                 |\n",
    "\n",
    "**Typical order in one block:**\n",
    "\n",
    "```python\n",
    "layers.Conv2D(...)\n",
    "layers.BatchNormalization()\n",
    "layers.Activation('relu')        # or use activation in Conv2D\n",
    "layers.MaxPooling2D(...)\n",
    "layers.Dropout(0.25)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Classification Block\n",
    "\n",
    "**Definition:** Map flattened feature maps to class probabilities via dense layers.\n",
    "\n",
    "| Layer                               | Purpose & When to Use                                              | Syntax Example                                    |\n",
    "| ----------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------- |\n",
    "| **Flatten**                         | Collapse spatial dims to 1D vector                                 | `layers.Flatten()`                                |\n",
    "| **GlobalAveragePooling2D** _(alt.)_ | Reduce each feature map to its average; fewer params than Flatten. | `layers.GlobalAveragePooling2D()`                 |\n",
    "| **Dense**                           | Fully-connected layer to learn combinations of features.           | `layers.Dense(128, activation='relu')`            |\n",
    "| **Dropout**                         | Further regularization before final output.                        | `layers.Dropout(0.5)`                             |\n",
    "| **Output Dense (multi-class)**      | Final logits → probabilities across N classes.                     | `layers.Dense(num_classes, activation='softmax')` |\n",
    "| **Output Dense (binary)**           | Single probability for two classes.                                | `layers.Dense(1, activation='sigmoid')`           |\n",
    "\n",
    "**Typical order:**\n",
    "\n",
    "```python\n",
    "layers.Flatten()                     # or GlobalAveragePooling2D()\n",
    "layers.Dense(128, activation='relu')\n",
    "layers.Dropout(0.5)\n",
    "layers.Dense(num_classes, activation='softmax')\n",
    "```\n",
    "\n",
    "To connect layers you put the output of the previous layer as the input of the current layer, example:\n",
    "\n",
    "```python\n",
    "input = keras.Input(shape=input_shape)\n",
    "model = layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224,224,3))(input)\n",
    "model = layers.Flatten()(model)\n",
    "```\n",
    "\n",
    "To get the whole model's architecture use the following: `model.summary()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4efd46",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "\n",
    "**Definition:**\n",
    "Compile your CNN by specifying the optimizer, loss, and metrics, then train it on your datasets using `model.fit()` without any callbacks.\n",
    "\n",
    "```python\n",
    "# 1. Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',                  # e.g. 'adam', 'sgd', or a configured tf.keras.optimizers.Optimizer\n",
    "    loss='categorical_crossentropy',   # for one-hot multi-class; use 'binary_crossentropy' for 2-class\n",
    "    metrics=['accuracy']               # list of metrics to track during training\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "history = model.fit(\n",
    "    train_ds,                          # tf.data.Dataset (or NumPy arrays) for training\n",
    "    validation_data=val_ds,           # tf.data.Dataset (or tuple) for validation\n",
    "    epochs=30                          # number of full passes through the training data\n",
    ")\n",
    "```\n",
    "\n",
    "**Explanation of Key Arguments:**\n",
    "\n",
    "- **`optimizer`**: algorithm that updates network weights (e.g., Adam adapts learning rates per parameter).\n",
    "- **`loss`**: objective function to minimize; chosen based on label encoding (categorical vs. binary).\n",
    "- **`metrics`**: additional performance measures displayed each epoch.\n",
    "- **`train_ds`**: your preprocessed and batched training dataset.\n",
    "- **`validation_data`**: held-out dataset to track generalization at the end of each epoch.\n",
    "- **`epochs`**: how many times the model sees the entire training set.\n",
    "\n",
    "The returned `history` object contains `history.history['loss']`, `['accuracy']`, `['val_loss']`, and `['val_accuracy']`, which you can plot to visualize training dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550d4c8",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "**Definition:**\n",
    "Assess the trained model’s performance on held-out test data by computing loss and metrics, and (optionally) generating detailed reports like confusion matrices.\n",
    "\n",
    "```python\n",
    "# 1. Compute loss & accuracy on the test set\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# 2. (Optional) Detailed classification metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Gather true labels and predictions\n",
    "y_true = np.concatenate([y.numpy() for x, y in test_ds], axis=0)\n",
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_idx = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_idx, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_idx, y_pred, target_names=test_ds.class_names))\n",
    "```\n",
    "\n",
    "**Explanation of Key Steps:**\n",
    "\n",
    "- **`model.evaluate(test_ds)`**:\n",
    "\n",
    "  - Runs the model on each batch in `test_ds`.\n",
    "  - Returns the loss and any metrics (e.g., accuracy) defined at compile time.\n",
    "\n",
    "- **`model.predict(test_ds)`**:\n",
    "\n",
    "  - Generates raw predictions (probabilities) for each test sample.\n",
    "\n",
    "- **`np.argmax(...)`**:\n",
    "\n",
    "  - Converts one-hot or probability vectors to class indices.\n",
    "\n",
    "- **`classification_report` / `confusion_matrix`**:\n",
    "\n",
    "  - From scikit-learn, provides precision/recall/F1 for each class and a matrix of true vs. predicted labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac5984",
   "metadata": {},
   "source": [
    "#### Hands-on Activity\n",
    "\n",
    "For the assigned dataset perform the following tasks:<br>\n",
    "**Task 1** : Structure your directory as shown in the Dataset Loading section<br>\n",
    "**Task 2** : Load the dataset and split it into training, validation, and test sets<br>\n",
    "**Task 3** : Create a new directory containing four subdirectories—one for each class<br>\n",
    "**Task 4** : Build the model architecture (feature-extraction and classification blocks), explaining your design choices as needed<br>\n",
    "**Task 5** : Plot the training curves (e.g., loss and accuracy) and assess whether the model is overfitting or underfitting<br>\n",
    "**Task 6** : Evaluate the final model on the test set and interpret the results<br>\n",
    "**Task 7** : Choose a preprocessing technique from the previous lab, apply it to your images, then repeat Tasks 1–6 on the preprocessed dataset. Discuss whether performance improved or declined—and why.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fefcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
